# Chapter 3.6 ‚Äî Monitoring & Observability

[‚Üê Previous: Configuration Management](05-configuration-management.md) | [Next: Unit 4 ‚Äî Version Control Systems ‚Üí](../04-DevOps-Tools-Landscape/01-version-control-systems.md)

---

## Overview

**Monitoring** tells you WHEN something is wrong. **Observability** tells you WHY. Together, they form the feedback loop that keeps systems reliable. Without monitoring and observability, you're flying blind ‚Äî you'll only discover problems when users complain.

---

## Monitoring vs Observability

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  MONITORING vs OBSERVABILITY                             ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  MONITORING                      OBSERVABILITY           ‚îÇ
‚îÇ  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê                      ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê           ‚îÇ
‚îÇ  "Is the system working?"        "Why is it broken?"     ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Dashboard alerts            ‚îú‚îÄ‚îÄ Trace requests      ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Threshold-based             ‚îú‚îÄ‚îÄ Correlate events    ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Known failure modes         ‚îú‚îÄ‚îÄ Unknown unknowns    ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Predefined queries          ‚îú‚îÄ‚îÄ Ad-hoc exploration  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ "CPU > 90% ‚Üí alert"        ‚îî‚îÄ‚îÄ "Why is checkout     ‚îÇ
‚îÇ                                       slow for users     ‚îÇ
‚îÇ                                       in Europe?"        ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Monitoring ‚äÇ Observability                              ‚îÇ
‚îÇ  (Monitoring is a subset of Observability)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Three Pillars of Observability

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  THE THREE PILLARS                                       ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ    LOGS      ‚îÇ  ‚îÇ   METRICS    ‚îÇ  ‚îÇ   TRACES     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  What        ‚îÇ  ‚îÇ  How much /  ‚îÇ  ‚îÇ  Where does  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  happened?   ‚îÇ  ‚îÇ  How many?   ‚îÇ  ‚îÇ  time go?    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Text events ‚îÇ  ‚îÇ  Numbers     ‚îÇ  ‚îÇ  Request     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  with        ‚îÇ  ‚îÇ  over time   ‚îÇ  ‚îÇ  journey     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  timestamps  ‚îÇ  ‚îÇ  (counters,  ‚îÇ  ‚îÇ  across      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ  gauges,     ‚îÇ  ‚îÇ  services    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ELK Stack   ‚îÇ  ‚îÇ  histograms) ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Loki        ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ  Jaeger      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Splunk      ‚îÇ  ‚îÇ  Prometheus  ‚îÇ  ‚îÇ  Zipkin      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  CloudWatch  ‚îÇ  ‚îÇ  Datadog     ‚îÇ  ‚îÇ  OpenTelemetry‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Best Practice: CORRELATE all three!                     ‚îÇ
‚îÇ  Log ‚Üí Metric ‚Üí Trace ‚Üí Root Cause                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Pillar 1: Logs

### Structured Logging

```json
// ‚ùå Unstructured (hard to parse)
"ERROR: Failed to process order 12345 for user john@example.com"

// ‚úÖ Structured (machine-readable, searchable)
{
  "timestamp": "2024-01-15T10:23:45.123Z",
  "level": "ERROR",
  "service": "order-service",
  "message": "Failed to process order",
  "order_id": "12345",
  "user_email": "john@example.com",
  "error_code": "PAYMENT_DECLINED",
  "trace_id": "abc123def456",
  "duration_ms": 2340
}
```

### Log Levels

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  LOG LEVELS (from most to least severe)                  ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  FATAL   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  System is unusable            ‚îÇ
‚îÇ  ERROR   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    Something failed              ‚îÇ
‚îÇ  WARN    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      Something unexpected          ‚îÇ
‚îÇ  INFO    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        Normal operations             ‚îÇ
‚îÇ  DEBUG   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          Detailed debugging info       ‚îÇ
‚îÇ  TRACE   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            Very detailed tracing         ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Production: INFO and above                              ‚îÇ
‚îÇ  Debugging:  DEBUG and above                             ‚îÇ
‚îÇ  Never in production: TRACE (too verbose)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### ELK Stack (Elasticsearch, Logstash, Kibana)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ELK STACK PIPELINE                                      ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇ  Apps    ‚îÇ‚îÄ‚îÄ‚ñ∫‚îÇ Logstash ‚îÇ‚îÄ‚îÄ‚ñ∫‚îÇElasticsearch ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  (logs)  ‚îÇ   ‚îÇ / Beats  ‚îÇ   ‚îÇ  (storage +  ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ (ingest) ‚îÇ   ‚îÇ   indexing)  ‚îÇ         ‚îÇ
‚îÇ                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ                                       ‚îÇ                  ‚îÇ
‚îÇ                                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ                                ‚îÇ   Kibana     ‚îÇ         ‚îÇ
‚îÇ                                ‚îÇ  (visualize  ‚îÇ         ‚îÇ
‚îÇ                                ‚îÇ   + search)  ‚îÇ         ‚îÇ
‚îÇ                                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Modern Alternative: Loki + Grafana (lighter weight)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Pillar 2: Metrics

### Prometheus Example

```yaml
# prometheus.yml - Prometheus configuration
global:
  scrape_interval: 15s      # How often to scrape targets
  evaluation_interval: 15s  # How often to evaluate rules

rule_files:
  - "alerts.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets: ['alertmanager:9093']

scrape_configs:
  - job_name: 'web-app'
    static_configs:
      - targets: ['web1:8080', 'web2:8080', 'web3:8080']
    metrics_path: /metrics

  - job_name: 'node-exporter'
    static_configs:
      - targets: ['web1:9100', 'web2:9100', 'web3:9100']
```

### Four Golden Signals (Google SRE)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  THE FOUR GOLDEN SIGNALS                                 ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  1. LATENCY                                              ‚îÇ
‚îÇ     How long requests take                               ‚îÇ
‚îÇ     ‚Üí histogram: http_request_duration_seconds           ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  2. TRAFFIC                                              ‚îÇ
‚îÇ     How much demand is hitting the system                ‚îÇ
‚îÇ     ‚Üí counter: http_requests_total                       ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  3. ERRORS                                               ‚îÇ
‚îÇ     Rate of failed requests                              ‚îÇ
‚îÇ     ‚Üí gauge: error_rate = errors / total_requests        ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  4. SATURATION                                           ‚îÇ
‚îÇ     How "full" the system is                             ‚îÇ
‚îÇ     ‚Üí gauge: cpu_usage_percent, memory_usage_percent     ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  If you can only monitor 4 things, monitor THESE.        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Alert Rules

```yaml
# alerts.yml - Prometheus alerting rules
groups:
  - name: web-app-alerts
    rules:
      # High error rate
      - alert: HighErrorRate
        expr: |
          sum(rate(http_requests_total{status=~"5.."}[5m]))
          /
          sum(rate(http_requests_total[5m])) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} (>5%)"

      # High latency
      - alert: HighLatency
        expr: |
          histogram_quantile(0.95, 
            rate(http_request_duration_seconds_bucket[5m])
          ) > 2.0
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High p95 latency"
          description: "95th percentile latency is {{ $value }}s (>2s)"

      # Pod not ready
      - alert: PodNotReady
        expr: kube_pod_status_ready{condition="true"} == 0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Pod {{ $labels.pod }} is not ready"
```

---

## Pillar 3: Distributed Traces

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  DISTRIBUTED TRACE: "Place Order" Request                ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Trace ID: abc-123-def-456                               ‚îÇ
‚îÇ  Total Duration: 1250ms                                  ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ API Gateway (50ms)                                  ‚îÇ
‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ Auth Service (30ms)                             ‚îÇ
‚îÇ  ‚îÇ                                                       ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Order Service (200ms)                               ‚îÇ
‚îÇ  ‚îÇ   ‚îú‚îÄ‚îÄ Inventory Service (80ms)                        ‚îÇ
‚îÇ  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Database Query (45ms)                       ‚îÇ
‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ Pricing Service (100ms)                         ‚îÇ
‚îÇ  ‚îÇ       ‚îî‚îÄ‚îÄ Cache Lookup (5ms)                          ‚îÇ
‚îÇ  ‚îÇ                                                       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ Payment Service (900ms)  ‚óÑ‚îÄ‚îÄ BOTTLENECK!            ‚îÇ
‚îÇ      ‚îú‚îÄ‚îÄ Fraud Check (150ms)                             ‚îÇ
‚îÇ      ‚îú‚îÄ‚îÄ Payment Gateway (700ms) ‚óÑ‚îÄ‚îÄ External API slow   ‚îÇ
‚îÇ      ‚îî‚îÄ‚îÄ Receipt Email (50ms)                            ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Without traces: "Orders are slow"                       ‚îÇ
‚îÇ  With traces: "Payment gateway is slow (700ms)"          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### OpenTelemetry (OTel)

```python
# OpenTelemetry instrumentation (Python example)
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.exporter.jaeger.thrift import JaegerExporter

# Setup
provider = TracerProvider()
jaeger_exporter = JaegerExporter(
    agent_host_name="jaeger",
    agent_port=6831,
)
provider.add_span_processor(BatchSpanProcessor(jaeger_exporter))
trace.set_tracer_provider(provider)
tracer = trace.get_tracer(__name__)

# Usage in application code
@app.route("/api/orders", methods=["POST"])
def create_order():
    with tracer.start_as_current_span("create_order") as span:
        span.set_attribute("user.id", request.user_id)
        
        with tracer.start_as_current_span("validate_inventory"):
            inventory = check_inventory(request.items)
        
        with tracer.start_as_current_span("process_payment"):
            payment = charge_card(request.payment_info)
            span.set_attribute("payment.amount", payment.amount)
        
        return {"order_id": order.id}
```

---

## Grafana Dashboard

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  GRAFANA DASHBOARD LAYOUT                                ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  üü¢ Service Health: All Systems Operational       ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Request Rate   ‚îÇ  ‚îÇ Error Rate     ‚îÇ  ‚îÇ  P95      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   12.3k/s      ‚îÇ  ‚îÇ   0.02%        ‚îÇ  ‚îÇ Latency   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà   ‚îÇ  ‚îÇ ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ  ‚îÇ  ‚îÇ  142ms   ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  CPU Usage by Node                                ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  web1: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  65%                    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  web2: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  48%                    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  web3: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë  78%  ‚ö†Ô∏è                ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  db1:  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  35%                    ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Data Sources: Prometheus + Loki + Jaeger                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Alerting Best Practices

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ALERTING PYRAMID                                        ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ         ‚ï±‚ï≤         PAGE (wake someone up)                ‚îÇ
‚îÇ        ‚ï±  ‚ï≤        ‚Üí Service is DOWN                     ‚îÇ
‚îÇ       ‚ï± P  ‚ï≤       ‚Üí Data loss risk                      ‚îÇ
‚îÇ      ‚ï±‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï≤      ‚Üí SLO breach                          ‚îÇ
‚îÇ     ‚ï± TICKET ‚ï≤     ‚Üí Create a ticket for next shift      ‚îÇ
‚îÇ    ‚ï±‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï≤    ‚Üí Degraded performance                 ‚îÇ
‚îÇ   ‚ï±    LOG     ‚ï≤   ‚Üí Log for investigation later         ‚îÇ
‚îÇ  ‚ï±‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï≤  ‚Üí Non-critical anomalies              ‚îÇ
‚îÇ ‚ï±‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï≤                                    ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Alert Fatigue = Too many alerts = All alerts ignored     ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Rules:                                                  ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Every alert must be ACTIONABLE                      ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ If you can't act on it, it's not an alert           ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Tune thresholds to reduce false positives           ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ Use severity levels consistently                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Real-World Scenario: Diagnosing a Slow Checkout

```
1. ALERT FIRES:
   "HighLatency: 95th percentile latency is 4.2s (>2s)"

2. CHECK METRICS (Grafana):
   ‚Üí Latency spike started at 14:23
   ‚Üí Error rate normal (0.1%)
   ‚Üí Only checkout endpoint affected

3. CHECK TRACES (Jaeger):
   ‚Üí Trace for slow checkout request shows:
     ‚îú‚îÄ‚îÄ API Gateway: 10ms ‚úÖ
     ‚îú‚îÄ‚îÄ Cart Service: 25ms ‚úÖ
     ‚îú‚îÄ‚îÄ Payment Service: 3800ms ‚ùå  ‚Üê Found it!
     ‚îÇ   ‚îî‚îÄ‚îÄ External API call: 3750ms ‚Üê Root cause
     ‚îî‚îÄ‚îÄ Notification: 15ms ‚úÖ

4. CHECK LOGS (Kibana):
   ‚Üí Filter: service=payment-service AND level=WARN
   ‚Üí "Payment gateway response time degraded"
   ‚Üí "Retry attempt 2 of 3 for transaction xyz"

5. ROOT CAUSE:
   ‚Üí Third-party payment gateway experiencing issues
   ‚Üí Action: Switch to backup payment provider
   ‚Üí Resolution time: 8 minutes (MTTD: 3m, MTTR: 5m)
```

---

## Troubleshooting Tips

| Problem | Cause | Solution |
|---------|-------|----------|
| Alert fatigue | Too many non-actionable alerts | Review and prune alerts; every alert must have a runbook |
| Missing context in logs | Unstructured logging | Adopt structured logging (JSON) with trace IDs |
| Can't correlate events | No shared identifiers | Add trace IDs to logs, metrics labels, and spans |
| Metrics cardinality explosion | Too many unique label values | Avoid high-cardinality labels (user IDs, request IDs) |
| Dashboard overload | Too many panels | Focus on Four Golden Signals; create role-specific views |
| Delayed alerts | Scrape interval too long | Reduce scrape interval; use push-based metrics for critical paths |

---

## Summary Table

| Concept | Description |
|---------|-------------|
| **Monitoring** | Watching known metrics for known failure modes |
| **Observability** | Understanding system behavior from external outputs |
| **Logs** | Timestamped text events describing what happened |
| **Metrics** | Numerical measurements over time (counters, gauges) |
| **Traces** | Request journey across distributed services |
| **Four Golden Signals** | Latency, Traffic, Errors, Saturation |
| **Prometheus** | Open-source metrics collection and alerting |
| **Grafana** | Visualization and dashboarding tool |
| **ELK Stack** | Elasticsearch + Logstash + Kibana for log management |
| **OpenTelemetry** | Vendor-neutral standard for traces, metrics, and logs |

---

## Quick Revision Questions

1. **What is the difference between monitoring and observability?**
   <details><summary>Answer</summary>Monitoring tells you WHEN something is wrong using predefined dashboards and thresholds (e.g., "CPU > 90%"). Observability tells you WHY something is wrong by letting you explore data with ad-hoc queries. Monitoring handles known unknowns; observability handles unknown unknowns. Monitoring is a subset of observability.</details>

2. **What are the three pillars of observability?**
   <details><summary>Answer</summary>1) Logs ‚Äî timestamped text records of events (what happened). 2) Metrics ‚Äî numerical measurements over time like request rate or CPU usage (how much/how many). 3) Traces ‚Äî the path of a request through distributed services (where time is spent). The key is correlating all three using shared identifiers like trace IDs.</details>

3. **What are the Four Golden Signals from Google SRE?**
   <details><summary>Answer</summary>1) Latency ‚Äî how long requests take. 2) Traffic ‚Äî demand on the system (requests per second). 3) Errors ‚Äî rate of failed requests. 4) Saturation ‚Äî how full the system is (CPU, memory, disk). If you can only monitor four things, monitor these.</details>

4. **What is alert fatigue, and how do you prevent it?**
   <details><summary>Answer</summary>Alert fatigue occurs when teams receive too many alerts, causing them to ignore or miss critical ones. Prevention: 1) Every alert must be actionable. 2) Tune thresholds to reduce false positives. 3) Use severity levels (page vs ticket vs log). 4) Each alert should have a runbook. 5) Regularly review and prune alert rules.</details>

5. **Why is structured logging preferred over unstructured logging?**
   <details><summary>Answer</summary>Structured logging (JSON format) makes logs machine-readable, enabling: 1) Easy parsing and indexing by log management tools. 2) Filtering by specific fields (user_id, error_code). 3) Correlation with traces via trace_id. 4) Aggregation and analysis at scale. Unstructured logs require regex parsing and are brittle to format changes.</details>

6. **How do distributed traces help diagnose performance issues?**
   <details><summary>Answer</summary>Distributed traces track a single request across multiple services, showing: 1) Which services were called. 2) How long each service took. 3) Where the bottleneck is. For example, a trace might reveal that a "slow checkout" is caused by a third-party payment gateway taking 3.7 seconds, not by your own services.</details>

---

[‚Üê Previous: Configuration Management](05-configuration-management.md) | [Next: Unit 4 ‚Äî Version Control Systems ‚Üí](../04-DevOps-Tools-Landscape/01-version-control-systems.md)
